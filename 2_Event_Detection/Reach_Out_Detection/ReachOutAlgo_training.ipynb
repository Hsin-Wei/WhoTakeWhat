{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#Reach out of IMU\n",
    "IMU_RO_file_path = r'C:\\Users\\NCTU\\Desktop\\WhoTakeWhat\\data\\IMU\\forRO\\training\\ReachOut'                     # use your path\n",
    "IMU_RO_all_files = glob.glob(os.path.join(IMU_RO_file_path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "IMU_RO_df_list = []\n",
    "\n",
    "for index, f in enumerate(IMU_RO_all_files):\n",
    "    df = pd.read_csv(f, header=None)\n",
    "    df.columns = ['earx', 'eary', 'earz', 'accx', 'accy', 'accz', 'gyrox', 'gyroy', 'gyroz', 'timestamp', 'sampleNum']\n",
    "    IMU_RO_df_list.append(df)\n",
    "    \n",
    "\n",
    "#Other of IMU\n",
    "IMU_Other_file_path = r'C:\\Users\\NCTU\\Desktop\\WhoTakeWhat\\data\\IMU\\forRO\\training\\Other'                     # use your path\n",
    "IMU_Other_all_files = glob.glob(os.path.join(IMU_Other_file_path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "IMU_Other_df_list = []\n",
    "\n",
    "for index, f in enumerate(IMU_Other_all_files):\n",
    "    df = pd.read_csv(f, header=None)\n",
    "    df.columns = ['earx', 'eary', 'earz', 'accx', 'accy', 'accz', 'gyrox', 'gyroy', 'gyroz', 'timestamp']\n",
    "    IMU_Other_df_list.append(df)\n",
    "#============================================== \n",
    "\n",
    "config_file_path = './config/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reach out data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取出各個reach out 的sample段 to list that each of element is np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IMU data of reaching out have 45 sample\n"
     ]
    }
   ],
   "source": [
    "IMU_RO_sampleAll = []\n",
    "\n",
    "for index, IMU_RO_raw_pd in enumerate(IMU_RO_df_list):\n",
    "    sampleCount = [x for x in np.unique(IMU_RO_raw_pd['sampleNum'].values) if not math.isnan(x)]\n",
    "    for count in sampleCount:\n",
    "        IMU_RO_sampleAll.append(IMU_RO_raw_pd.loc[IMU_RO_raw_pd['sampleNum']==count, ['accx', 'accy', 'accz', 'gyrox', 'gyroy', 'gyroz']].values)\n",
    "\n",
    "print(\"Training IMU data of reaching out have %d sample\" % (len(IMU_RO_sampleAll)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate windows size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much samples in one sec (Must need even)\n",
    "sampleRate_IMU_acc = 100\n",
    "\n",
    "# Config file\n",
    "config_file = {}\n",
    "config_file['sampling_rate'] = sampleRate_IMU_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取最平均值↓↓↓↓↓↓↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU window:  3.0\n",
      "Windows Size = 3\n"
     ]
    }
   ],
   "source": [
    "windowSize_IMU_sa = 0\n",
    "lenTemp = []\n",
    "for IMU_RO_sample in IMU_RO_sampleAll:\n",
    "    lenTemp.append(len(IMU_RO_sample))\n",
    "\n",
    "windowSize_IMU_sa = np.mean(lenTemp)\n",
    "windowSize_IMU = -(-(windowSize_IMU_sa)//sampleRate_IMU_acc)\n",
    "print ('IMU window: ', windowSize_IMU)\n",
    "\n",
    "        \n",
    "#Convert to sec\n",
    "# windowSize_sec = max(windowSize_IMU)\n",
    "windowSize_sec = windowSize_IMU\n",
    "\n",
    "windowSize_sec = int(windowSize_sec)\n",
    "\n",
    "config_file['windows_size'] = windowSize_sec\n",
    "\n",
    "print ('Windows Size = %d' % windowSize_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(config_file, open((config_file_path + 'config.pkl'), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取最大值↓↓↓↓↓↓↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #IMU\n",
    "# windowSize_IMU_sa = 0\n",
    "# for IMU_RO_sample in IMU_RO_sampleAll:\n",
    "#     if windowSize_IMU_sa < IMU_RO_sample.shape[0]:\n",
    "#         windowSize_IMU_sa = IMU_RO_sample.shape[0]\n",
    "        \n",
    "# windowSize_IMU = -(-(windowSize_IMU_sa)//sampleRate_IMU)\n",
    "# print ('IMU window: ', windowSize_IMU)\n",
    "\n",
    "# #Kinect    \n",
    "# windowSize_Kinect_sa = 0\n",
    "# for Kinect_RO_sample in Kinect_RO_sampleAll:\n",
    "#     if windowSize_Kinect_sa < Kinect_RO_sample.shape[0]:\n",
    "#         windowSize_Kinect_sa = Kinect_RO_sample.shape[0]\n",
    "\n",
    "# windowSize_Kinect = -(-(windowSize_Kinect_sa)//sampleRate_Kinect)\n",
    "# print ('Kinect window: ', windowSize_Kinect)\n",
    "        \n",
    "# #Convert to sec\n",
    "# windowSize_sec = max(windowSize_IMU, windowSize_Kinect)\n",
    "\n",
    "# windowSize_sec = int(windowSize_sec)\n",
    "\n",
    "# # windowSize_sec = 3\n",
    "# print ('Windows Size = %d' % windowSize_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut other data by windows size (overlapping half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IMU data of Other have 481 sample\n"
     ]
    }
   ],
   "source": [
    "#IMU other data\n",
    "IMU_Other_sampleAll = []\n",
    "for index, IMU_Other_raw_pd in enumerate(IMU_Other_df_list):\n",
    "    ranges = list(range(0, IMU_Other_raw_pd.shape[0], windowSize_sec*sampleRate_IMU_acc//2))\n",
    "    for start in ranges:\n",
    "        end = start+windowSize_sec*sampleRate_IMU_acc\n",
    "        if end >= len(IMU_Other_raw_pd):\n",
    "            continue\n",
    "        IMU_Other_sampleAll.append(IMU_Other_raw_pd.loc[start:end-1, ['accx', 'accy', 'accz', 'gyrox', 'gyroy', 'gyroz']].values)\n",
    "\n",
    "print(\"Training IMU data of Other have %d sample\" % len(IMU_Other_sampleAll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature of IMU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_feature_IMU import extract_feature_IMU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_feature_gyro_IMU(IMU_sample): #input np.array shape = (N, 3)\n",
    "\n",
    "#     ##Mean (1, 3)\n",
    "#     IMU_mean = np.mean(IMU_sample, axis=0) \n",
    "    \n",
    "#     ##Skewness\n",
    "#     IMU_skew = skew(IMU_sample, axis=0)\n",
    "    \n",
    "#     ##Kurtosis\n",
    "#     IMU_kurtosis = kurtosis(IMU_sample, axis=0)\n",
    "    \n",
    "#     ##Mean Magnitude (1,)\n",
    "#     summ = 0.0\n",
    "#     for IMU_sample_sample in IMU_sample:\n",
    "#         tempSqur = 0.0\n",
    "#         for i in range(0, len(IMU_sample_sample)):\n",
    "#             tempSqur += IMU_sample_sample[i]**2\n",
    "#         summ = tempSqur**0.5\n",
    "#     IMU_MM = (summ/IMU_sample.shape[0])\n",
    "\n",
    "#     ##Variance (1, 3)\n",
    "#     IMU_var = np.var(IMU_sample, axis=0) \n",
    "\n",
    "#     ##Median (1, 3)\n",
    "#     IMU_median = np.median(IMU_sample, axis=0)\n",
    "    \n",
    "#     #-------------------------------------------\n",
    "#     #\n",
    "    \n",
    "#     #-------------------------------------------\n",
    "#     #Time feature\n",
    "\n",
    "#     ##Mean of 1 sec (1, 3*windowSize)...\n",
    "#     #feature count is windowsSize/sec. \n",
    "#     #Each of mean of reaching out are 100 samples.\n",
    "#     oneSample = []\n",
    "#     for start in range(0, windowSize_sec*sampleRate_IMU_gyro, sampleRate_IMU_gyro):\n",
    "#         end = start + sampleRate_IMU_gyro\n",
    "#         tempSamples = IMU_sample[start:end]\n",
    "#         oneSample.extend(np.mean(tempSamples, axis=0).tolist())\n",
    "#     IMU_meanOf1sec = oneSample\n",
    "\n",
    "#     #combine together\n",
    "#     features = []\n",
    "#     features.extend(IMU_mean.tolist())\n",
    "#     features.extend(IMU_skew.tolist())\n",
    "#     features.extend(IMU_kurtosis.tolist())\n",
    "#     features.append(IMU_MM)\n",
    "#     features.extend(IMU_var.tolist())\n",
    "#     features.extend(IMU_median.tolist())\n",
    "#     features.extend(IMU_meanOf1sec)\n",
    "    \n",
    "#     return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補足data長度到windows size(前後補)&Split data into Training, Validation and Testing(6/2/2) & Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/sc_IMU.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_IMU = []\n",
    "y_IMU = []\n",
    "\n",
    "#add RO into X_IMU & y_IMU\n",
    "for IMU_RO_sample in IMU_RO_sampleAll:\n",
    "    lengthOflack = sampleRate_IMU_acc*windowSize_sec-len(IMU_RO_sample)\n",
    "    if lengthOflack > 0:\n",
    "#         IMU_RO_sample_filltoprior = np.concatenate( \n",
    "#                                   ([IMU_RO_sample[0].tolist()] * lengthOflack, IMU_RO_sample),\n",
    "#                                   axis=0)\n",
    "#         IMU_RO_sample_filltoPandR = np.concatenate(\n",
    "#                                   ([IMU_RO_sample[0].tolist()] * (lengthOflack//2), IMU_RO_sample, [IMU_RO_sample[-1].tolist()] * (-(-lengthOflack//2))), \n",
    "#                                   axis=0)\n",
    "#         IMU_RO_sample_filltorear = np.concatenate(\n",
    "#                                   (IMU_RO_sample, [IMU_RO_sample[-1].tolist()] * lengthOflack), \n",
    "#                                   axis=0)\n",
    "\n",
    "        IMU_RO_sample_filltoprior = np.concatenate( \n",
    "                                  ([[0, 0, 0, 0, 0, 0]] * lengthOflack, IMU_RO_sample),\n",
    "                                  axis=0)\n",
    "        IMU_RO_sample_filltoPandR = np.concatenate(\n",
    "                                  ([[0, 0, 0, 0, 0, 0]] * (lengthOflack//2), IMU_RO_sample, [[0, 0, 0, 0, 0, 0]] * (-(-lengthOflack//2))), \n",
    "                                  axis=0)\n",
    "        IMU_RO_sample_filltorear = np.concatenate(\n",
    "                                  (IMU_RO_sample, [[0, 0, 0, 0, 0, 0]] * lengthOflack), \n",
    "                                  axis=0)\n",
    "    else:\n",
    "        IMU_RO_sample_filltoprior = IMU_RO_sample\n",
    "        IMU_RO_sample_filltoPandR = IMU_RO_sample\n",
    "        IMU_RO_sample_filltorear = IMU_RO_sample\n",
    "\n",
    "\n",
    "    features_prior = extract_feature_IMU(IMU_RO_sample_filltoprior)\n",
    "    features_PandR = extract_feature_IMU(IMU_RO_sample_filltoPandR)\n",
    "    features_rear = extract_feature_IMU(IMU_RO_sample_filltorear)\n",
    "\n",
    "    #add into X_IMU\n",
    "    X_IMU.append(features_prior)\n",
    "    y_IMU.append(1)\n",
    "    X_IMU.append(features_PandR)\n",
    "    y_IMU.append(1)\n",
    "    X_IMU.append(features_rear)\n",
    "    y_IMU.append(1)\n",
    "    \n",
    "\n",
    "#add Other into X_IMU & y_IMU\n",
    "for IMU_Other_sample in IMU_Other_sampleAll:\n",
    "    features = extract_feature_IMU(IMU_Other_sample)\n",
    "    #add into X\n",
    "    X_IMU.append(features)\n",
    "    y_IMU.append(0)\n",
    "    \n",
    "\n",
    "##Split X_IMU, y_IMU into training and testing(7/3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_IMU_train, X_IMU_test, y_IMU_train, y_IMU_test = train_test_split(X_IMU, y_IMU, test_size=0.2, random_state=0)\n",
    "# X_IMU_train, X_IMU_val, y_IMU_train, y_IMU_val = train_test_split(X_IMU_train, y_IMU_train, test_size=0.25, random_state=0)\n",
    "X_IMU_train, X_IMU_val, y_IMU_train, y_IMU_val = train_test_split(X_IMU, y_IMU, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "#Standard\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_IMU = StandardScaler()\n",
    "sc_IMU.fit(X_IMU_train)\n",
    "X_IMU_train_std = sc_IMU.transform(X_IMU_train)\n",
    "X_IMU_val_std = sc_IMU.transform(X_IMU_val)\n",
    "# X_IMU_test_std = sc_IMU.transform(X_IMU_test)\n",
    "\n",
    "# Persist scaler\n",
    "joblib.dump(sc_IMU, './models/sc_IMU.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many features: 256\n"
     ]
    }
   ],
   "source": [
    "print ('How many features: %d' % len(extract_feature_IMU(IMU_RO_sample_filltoprior)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data的比率 of IMU\n",
      "{0: 337, 1: 94}\n"
     ]
    }
   ],
   "source": [
    "print('Training data的比率 of IMU')\n",
    "uni ,count = np.unique(y_IMU_train, return_counts=True)\n",
    "print (dict(zip(uni, count)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data的比率 of IMU\n",
      "{0: 144, 1: 41}\n"
     ]
    }
   ],
   "source": [
    "print('Validation data的比率 of IMU')\n",
    "uni ,count = np.unique(y_IMU_val, return_counts=True)\n",
    "print (dict(zip(uni, count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 丟入model 看結果(緊張..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Decision Tree=======\n",
      "[IMU performance]\n",
      "Validation accuracy: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/tree_IMU.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('======Decision Tree=======')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# criterion : impurity function\n",
    "# max_depth : maximum depth of tree\n",
    "# random_state : seed of random number generator\n",
    "##IMU\n",
    "tree_IMU = DecisionTreeClassifier(criterion='gini', \n",
    "                              max_depth=None, \n",
    "                              random_state=4,\n",
    "                                 max_features='auto')\n",
    "tree_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "print('[IMU performance]')\n",
    "#Validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_IMU_pred = tree_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = tree_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "#Persist model\n",
    "joblib.dump(tree_IMU, './models/tree_IMU.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Random Forest=======\n",
      "[IMU performance]\n",
      "Validation accuracy: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/forest_IMU.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('======Random Forest=======')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# criterion : impurity function\n",
    "# n_estimators :  number of decision trees\n",
    "# random_state : seed used by the random number generator\n",
    "# n_jobs : number of cores for parallelism\n",
    "#IMU\n",
    "forest_IMU = RandomForestClassifier(criterion='entropy',\n",
    "                                max_depth=10,\n",
    "                                n_estimators=500, \n",
    "                                random_state=0,\n",
    "                                max_features='auto',\n",
    "                                n_jobs=-1)\n",
    "forest_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "print('[IMU performance]')\n",
    "#Validation\n",
    "y_IMU_pred = forest_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = forest_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "\n",
    "#Persist model\n",
    "joblib.dump(forest_IMU, './models/forest_IMU.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======KNN=======\n",
      "[IMU performance]\n",
      "Validation accuracy: 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/knn_IMU.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('======KNN=======')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# p=2 and metric='minkowski' means the Euclidean Distance\n",
    "##IMU\n",
    "knn_IMU = KNeighborsClassifier(n_neighbors=10, \n",
    "                               weights='uniform', \n",
    "                               algorithm='auto', \n",
    "                               leaf_size=5,\n",
    "                               p=3, \n",
    "                               metric='minkowski', \n",
    "                               n_jobs=-1)\n",
    "\n",
    "knn_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "print('[IMU performance]')\n",
    "#Validation\n",
    "y_IMU_pred = knn_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = knn_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "\n",
    "#Persist model\n",
    "joblib.dump(knn_IMU, './models/knn_IMU.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====SVM=======\n",
      "#[IMU performance]#\n",
      "[Linear SVC]\n",
      "Validation accuracy: 0.99\n",
      "[Poly SVC]\n",
      "Validation accuracy: 0.99\n",
      "[sigmoid SVC]\n",
      "Validation accuracy: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/svm_sigmoid_IMU.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('=====SVM=======')\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# kernel: the kernel function, can be 'linear', 'poly', 'sigmoid', ...etc\n",
    "# C is the hyperparameter for the error penalty term\n",
    "##IMU\n",
    "svm_linear_IMU = SVC(kernel='linear', C=10000.0, random_state=0, probability=True)\n",
    "\n",
    "svm_linear_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "print('#[IMU performance]#')\n",
    "#Validation\n",
    "print('[Linear SVC]')\n",
    "y_IMU_pred = svm_linear_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = svm_linear_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "##poly\n",
    "svm_poly_IMU = SVC(kernel='poly', C=10000.0, degree=1, random_state=2, probability=True)\n",
    "\n",
    "svm_poly_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "#Validation\n",
    "print('[Poly SVC]')\n",
    "y_IMU_pred = svm_poly_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = svm_poly_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "##sigmoid\n",
    "svm_sigmoid_IMU = SVC(kernel='sigmoid', C=1.0, degree=100, random_state=0, probability=True)\n",
    "\n",
    "svm_sigmoid_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "#Validation\n",
    "print('[sigmoid SVC]')\n",
    "y_IMU_pred = svm_sigmoid_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = svm_sigmoid_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "\n",
    "#Persist model\n",
    "joblib.dump(svm_linear_IMU, './models/svm_linear_IMU.pkl')\n",
    "joblib.dump(svm_poly_IMU, './models/svm_poly_IMU.pkl')\n",
    "joblib.dump(svm_sigmoid_IMU, './models/svm_sigmoid_IMU.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Neural network=======\n",
      "#[IMU performance]#\n",
      "Validation accuracy: 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/NN_IMU.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('======Neural network=======')\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "NN_IMU = MLPClassifier(solver='lbfgs', alpha=0.0001, activation='logistic', learning_rate='constant', learning_rate_init=0.001,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "NN_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "print('#[IMU performance]#')\n",
    "#Validation\n",
    "y_IMU_pred = NN_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "\n",
    "\n",
    "#Persist model\n",
    "joblib.dump(NN_IMU, './models/NN_IMU.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(X_train):\n",
    "    y_pred_ensemble = []\n",
    "    y_pred_ensemble.append(tree_IMU.predict(X_train))\n",
    "    y_pred_ensemble.append(forest_IMU.predict(X_train))\n",
    "    y_pred_ensemble.append(knn_IMU.predict(X_train))\n",
    "    y_pred_ensemble.append(svm_linear_IMU.predict(X_train))\n",
    "    y_pred_ensemble.append(svm_poly_IMU.predict(X_train))\n",
    "    y_pred_ensemble.append(svm_sigmoid_IMU.predict(X_train))\n",
    "    y_pred_ensemble.append(NN_IMU.predict(X_train))\n",
    "    y_pred_ensemble = np.array(y_pred_ensemble).T\n",
    "    y_pred = []\n",
    "    for y_seg in y_pred_ensemble:\n",
    "        y_seg = y_seg.tolist()\n",
    "        if y_seg.count(0) > y_seg.count(1):\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(1)\n",
    "    #     unique, counts = numpy.unique(y_seg, return_counts=True)\n",
    "    #     dict(zip(unique, counts))\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "y_IMU_pred = ensemble(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# import itertools\n",
    "\n",
    "# voting_IMU, best_w, best_score = None, (), -1\n",
    "# for a, b, c, d, e, f, g in list(itertools.permutations(range(0, 7))):  # try some weight combination\n",
    "#     voting_IMU_temp = VotingClassifier(\n",
    "#                         estimators=[('tree', tree_IMU), ('forest', forest_IMU), ('knn', knn_IMU),\n",
    "#                                     ('svm_linear', svm_linear_IMU), ('svm_poly', svm_poly_IMU), ('svm_rbf', svm_rbf_IMU),\n",
    "#                                     ('NN', NN_IMU)],\n",
    "#                           voting='soft',\n",
    "#                           weights=[a, b, c, d, e, f, g])\n",
    "#     scores = cross_val_score(\n",
    "#         estimator=voting_IMU_temp, X=X_IMU_train_std, y=y_IMU_train, cv=10, scoring='roc_auc')\n",
    "#     print('%s: %.3f (+/- %.3f)' % ((a, b, c, d, e, f, g), scores.mean(), scores.std()))\n",
    "#     if best_score < scores.mean():\n",
    "#         voting_IMU, best_w, best_score = voting_IMU_temp, (a, b, c, d, e, f, g), scores.mean()\n",
    "\n",
    "# print('\\nBest %s: %.3f' % (best_w, best_score))\n",
    "\n",
    "# #Persist model\n",
    "# joblib.dump(voting_IMU, './models/Voting_IMU.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating real world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "X_combined_IMU_All = []\n",
    "y_combined_IMU_All = []\n",
    "\n",
    "numberOfSampleAll = 30\n",
    "##先給0~X Other then replace RO in random place\n",
    "for random_Other_sample in random.sample(IMU_Other_sampleAll, numberOfSampleAll):\n",
    "    X_combined_IMU_All.append(random_Other_sample)\n",
    "    y_combined_IMU_All.append(0)\n",
    "\n",
    "\n",
    "insertROcount = 10\n",
    "for index, random_RO_sample in zip(np.random.randint(numberOfSampleAll, size=insertROcount), random.sample(IMU_RO_sampleAll, insertROcount)):\n",
    "    X_combined_IMU_All[index] = random_RO_sample\n",
    "    y_combined_IMU_All[index] = 1\n",
    "    \n",
    "##flatten\n",
    "X_combined_IMU_fla = []\n",
    "y_combined_IMU_fla = []\n",
    "\n",
    "for s, c in zip(X_combined_IMU_All, y_combined_IMU_All):\n",
    "    X_combined_IMU_fla.extend(s.tolist())\n",
    "    listofzerosOrOne = [c] * s.shape[0]\n",
    "    y_combined_IMU_fla.extend(listofzerosOrOne)\n",
    "    \n",
    "##Segmentation(by windows Size, and Overlapping= windows size - 1 sec)\n",
    "overlapping = windowSize_sec - 1\n",
    "X_combined_IMU_seg = [] \n",
    "\n",
    "for start in range(0, len(X_combined_IMU_fla), windowSize_sec*sampleRate_IMU_acc - overlapping*sampleRate_IMU_acc):\n",
    "    end = start + sampleRate_IMU_acc*windowSize_sec\n",
    "    if len(X_combined_IMU_fla[start:end]) < sampleRate_IMU_acc*windowSize_sec:\n",
    "        continue\n",
    "    else:\n",
    "        X_combined_IMU_seg.append(X_combined_IMU_fla[start:end])\n",
    "        \n",
    "# ##feature extraction\n",
    "X_combined_IMU = []\n",
    "\n",
    "for X_combined_IMU_seg_sample in X_combined_IMU_seg:\n",
    "    X_combined_IMU.append(extract_feature_IMU(np.array(X_combined_IMU_seg_sample)))\n",
    "        \n",
    "##Normalization\n",
    "X_combined_IMU_std = sc_IMU.transform(X_combined_IMU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將Pred結果展開成sample比較 #Overlapping 實際執行秒數 = (Sec*Num)-[(Num-1)*Overlap]\n",
    "def pred_flatToSamples_IMU(y_pred):\n",
    "    allofSec = windowSize_sec*len(y_pred)-(len(y_pred)-1)*overlapping\n",
    "    y_pred_sample = [0] * (allofSec*sampleRate_IMU_acc)\n",
    "    for pred, index in zip(y_pred, range(0, allofSec, windowSize_sec-overlapping)):\n",
    "        if pred == 1:\n",
    "            start = index*sampleRate_IMU_acc\n",
    "            end = start + sampleRate_IMU_acc*windowSize_sec\n",
    "            listofOne = [1] * (sampleRate_IMU_acc*windowSize_sec)\n",
    "            y_pred_sample[start:end] = listofOne\n",
    "    return y_pred_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IMU--\n",
      "Decision tree \n",
      "-DTW: 0.0\n",
      "-Accuracy: 0.87\n",
      "Random forest \n",
      "-DTW: 0.0\n",
      "-Accuracy: 0.90\n",
      "KNN \n",
      "-DTW: 0.0\n",
      "-Accuracy: 0.90\n",
      "SVM linear \n",
      "-DTW: 0.0\n",
      "-Accuracy: 0.88\n",
      "SVM poly \n",
      "-DTW: 0.0\n",
      "-Accuracy: 0.88\n",
      "SVM sigmoid \n",
      "-DTW: 289.0\n",
      "-Accuracy: 0.78\n",
      "NN \n",
      "-DTW: 0.0\n",
      "-Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "print('--IMU--')\n",
    "tree_IMU = joblib.load('./models/tree_IMU.pkl')\n",
    "y_pred = tree_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "# plot(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis])\n",
    "# plot(np.array(y_pred_sample)[:,np.newaxis])\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('Decision tree \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "forest_IMU = joblib.load('./models/forest_IMU.pkl')\n",
    "y_pred = forest_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('Random forest \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "knn_IMU = joblib.load('./models/knn_IMU.pkl')\n",
    "y_pred = knn_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('KNN \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "svm_linear_IMU = joblib.load('./models/svm_linear_IMU.pkl')\n",
    "y_pred = svm_linear_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('SVM linear \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "svm_poly_IMU = joblib.load('./models/svm_poly_IMU.pkl')\n",
    "y_pred = svm_poly_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('SVM poly \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "svm_sigmoid_IMU = joblib.load('./models/svm_sigmoid_IMU.pkl')\n",
    "y_pred = svm_sigmoid_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('SVM sigmoid \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "NN_IMU = joblib.load('./models/NN_IMU.pkl')\n",
    "y_pred = NN_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('NN \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembnle \n",
      "-DTW: 0.0\n",
      "-Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "y_pred = ensemble(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('Ensembnle \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-9e1622b385b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiencing real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMU_rW_pd = pd.read_csv('D:/GoogleDrive/Graduate/Research/Research_HsinWei/Programs/data/realWorldData/raw_data_RW01.csv', header=None)\n",
    "# IMU_rW_pd = pd.read_csv('D:/GoogleDrive/Graduate/Research/Research_HsinWei/Programs/data/IMUData/ReachOut/HW_raw_acc_RO_02.csv', header=None)\n",
    "\n",
    "IMU_rW_pd.columns = ['eaccx', 'eaccy', 'eaccz', 'accx', 'accy', 'accz', 'gyrox', 'gyroy', 'gyroz', 'timestamp']\n",
    "\n",
    "IMU_rW = IMU_rW_pd[['accx', 'accy', 'accz', 'gyrox', 'gyroy', 'gyroz']].values.tolist()\n",
    "\n",
    "##Segmentation(by windows Size, and Overlapping= windows size - 1 sec)\n",
    "overlapping = windowSize_sec - 1\n",
    "X_rW_IMU_seg = []\n",
    "\n",
    "for start in range(0, len(IMU_rW), windowSize_sec*sampleRate_IMU_acc - overlapping*sampleRate_IMU_acc):\n",
    "    end = start + sampleRate_IMU_acc*windowSize_sec\n",
    "    if len(IMU_rW[start:end]) < sampleRate_IMU_acc*windowSize_sec:\n",
    "        break\n",
    "    else:\n",
    "        X_rW_IMU_seg.append(IMU_rW[start:end])\n",
    "        \n",
    "#Preprocessing\n",
    "X_rW_IMU_seg_conv = []\n",
    "for X_rW_IMU_seg_sam in X_rW_IMU_seg:\n",
    "    X_rW_IMU_seg_conv.append(X_rW_IMU_seg_sam)\n",
    "        \n",
    "##feature extraction\n",
    "X_rW_IMU = []\n",
    "for X_rW_IMU_seg_sample in X_rW_IMU_seg_conv:\n",
    "    X_rW_IMU.append(extract_feature_IMU(np.array(X_rW_IMU_seg_sample)))\n",
    "        \n",
    "##Normalization\n",
    "X_rW_IMU_std = sc_IMU.transform(X_rW_IMU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kinect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Kinect_rW_pd = pd.read_csv('D:/GoogleDrive/Graduate/Research/Research_HsinWei/Programs/data/realWorldData/VSFile_RW01.csv', header=None)\n",
    "Kinect_rW_pd.columns = ['WristRight_x', 'WristRight_y', 'WristRight_z', \n",
    "                  'WristLeft_x', 'WristLeft_y', 'WristLeft_z', \n",
    "                  'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z',\n",
    "                  'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "                  'ShoulderRight_x', 'ShoulderRight_y', 'ShoulderRight_z',\n",
    "                  'ShoulderLeft_x', 'ShoulderLeft_y', 'ShoulderLeft_z',\n",
    "                  'SkeletonID', 'Head_image_x', 'Head_image_y', 'timestamp']\n",
    "\n",
    "Kinect_rW_pd_ntime = Kinect_rW_pd[['WristRight_x', 'WristRight_y', 'WristRight_z', \n",
    "                  'WristLeft_x', 'WristLeft_y', 'WristLeft_z', \n",
    "                  'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z',\n",
    "                  'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "                  'ShoulderRight_x', 'ShoulderRight_y', 'ShoulderRight_z',\n",
    "                  'ShoulderLeft_x', 'ShoulderLeft_y', 'ShoulderLeft_z',\n",
    "                  'SkeletonID', 'Head_image_x', 'Head_image_y']]\n",
    "\n",
    "Kinect_rW = Kinect_rW_pd_ntime.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed into models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_IMU_pred = ensemble(X_rW_IMU_std)\n",
    "print(y_IMU_pred)\n",
    "IMU_sample_rw_pred = pred_flatToSamples_IMU(y_IMU_pred)\n",
    "\n",
    "# #Aligning\n",
    "# from datetime import datetime\n",
    "# IMU_rW_time = IMU_rW_pd['timestamp']\n",
    "# Kinect_rW_time = Kinect_rW_pd['timestamp']\n",
    "\n",
    "# startIndex_IMU = 0\n",
    "# start_Kinect = datetime.strptime(Kinect_rW_time[0], '%H:%M:%S:%f')\n",
    "# IMU_rW_time = pd.to_datetime(IMU_rW_time, format='%H:%M:%S:%f')\n",
    "# for index, IMU_timestamp in zip(range(0, len(IMU_rW_time)), IMU_rW_time):\n",
    "#     if IMU_timestamp < start_Kinect:\n",
    "#         continue\n",
    "#     else:\n",
    "#         startIndex_IMU = index\n",
    "#         break\n",
    "        \n",
    "# IMU_sample_rw_pred = IMU_sample_rw_pred[startIndex_IMU:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sign IMU result in Kinect video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sign IMU result in Kinect video\n",
    "IMU_result_inKinect = []\n",
    "\n",
    "IMU_rW_time = pd.to_datetime(IMU_rW_pd['timestamp'], format='%H:%M:%S:%f')\n",
    "Kinect_rW_time = pd.to_datetime(Kinect_rW_pd['timestamp'], format='%H:%M:%S:%f')\n",
    "i = 0\n",
    "for Kinect_rW_timestamp in Kinect_rW_time:\n",
    "    for si in range(i, len(IMU_rW_time)):\n",
    "        if IMU_rW_time[si] <= Kinect_rW_timestamp and Kinect_rW_timestamp < IMU_rW_time[si+1]:\n",
    "            IMU_result_inKinect.append(IMU_sample_rw_pred[i])\n",
    "            i = si\n",
    "            break\n",
    "            \n",
    "# IMU_Kinect_sample_rw_pred = pd.DataFrame(np.array([IMU_result_inKinect, Kinect_sample_rw_pred]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to csv include result of predicting, headX_video, headY_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([pd.Series(IMU_result_inKinect), Kinect_rW_pd[['Head_image_x', 'Head_image_y', 'timestamp']]], ignore_index=True, axis=1)\n",
    "\n",
    "result.to_csv('D:/GoogleDrive/Graduate/Research/Research_HsinWei/Programs/data/realWorldData/ReachOutResult.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 測試真實的testing data看效果如何\n",
    "- IMU加更多的feature..(切更細的mean(O), Correlation, Covariance..)\n",
    "- Kinect加angle相關的atrribute, 並且座標zero點在自己身上,不會依據距離遠近而誤判\n",
    "- Kinect & IMU feature 合併的話??不是個別判斷\n",
    "- 程式部分\n",
    "    - 將extract feature寫成function(O)\n",
    "    - set sample/sec to var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE\n",
    "- 實驗重作...(O)\n",
    "- 程式部分\n",
    "    - 將extract feature寫成function(O)\n",
    "    - set sample/sec to var(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to csv include percentage, headX_video, headY_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([percentage, df[['HeadX_Video', 'HeadY_Video', 'TimeStamp']]], axis=1)\n",
    "\n",
    "result.to_csv('C:\\Research_temp\\data\\Result\\ReachOutResult.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path = r'D:\\GoogleDrive\\Graduate\\Research\\Research_HsinWei\\Programs\\data\\IMUData\\ReachOut'                     # use your path\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in range(10), range(11):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
