{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "#Reach out of IMU\n",
    "#********Based on Earth coordinate system********\n",
    "IMU_RO_file_path = r'D:\\GoogleDrive\\Graduate\\Research\\Research_HsinWei\\Programs\\data\\IMUData\\ReachOut'                     # use your path\n",
    "IMU_RO_all_files = glob.glob(os.path.join(IMU_RO_file_path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "IMU_RO_df_list = []\n",
    "\n",
    "for index, f in enumerate(IMU_RO_all_files):\n",
    "    df = pd.read_csv(f, header=None)\n",
    "    df.columns = ['x', 'y', 'z', 'timestamp', 'sampleNum']\n",
    "    IMU_RO_df_list.append(df)\n",
    "\n",
    "#Other of IMU\n",
    "IMU_Other_file_path = r'D:\\GoogleDrive\\Graduate\\Research\\Research_HsinWei\\Programs\\data\\IMUData\\Other'                     # use your path\n",
    "IMU_Other_all_files = glob.glob(os.path.join(IMU_Other_file_path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "IMU_Other_df_list = []\n",
    "\n",
    "for index, f in enumerate(IMU_Other_all_files):\n",
    "    df = pd.read_csv(f, header=None)\n",
    "    df.columns = ['x', 'y', 'z', 'timestamp']\n",
    "    IMU_Other_df_list.append(df)\n",
    "    \n",
    "#==============================================    \n",
    "\n",
    "#Reach out of Kinect\n",
    "#********Based on Kinect coordinate system********\n",
    "Kinect_RO_file_path = r'D:\\GoogleDrive\\Graduate\\Research\\Research_HsinWei\\Programs\\data\\KinectData\\ReachOut'                     # use your path\n",
    "Kinect_RO_all_files = glob.glob(os.path.join(Kinect_RO_file_path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "Kinect_RO_df_list = []\n",
    "\n",
    "for index, f in enumerate(Kinect_RO_all_files):\n",
    "    df = pd.read_csv(f, header=None)\n",
    "    df.columns = ['WristRight_x', 'WristRight_y', 'WristRight_z', \n",
    "                  'WristLeft_x', 'WristLeft_y', 'WristLeft_z', \n",
    "                  'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z',\n",
    "                  'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "                  'ShoulderRight_x', 'ShoulderRight_y', 'ShoulderRight_z',\n",
    "                  'ShoulderLeft_x', 'ShoulderLeft_y', 'ShoulderLeft_z',\n",
    "                  'SkeletonID', 'Head_image_x', 'Head_image_y', 'timestamp', 'sampleNum']\n",
    "    Kinect_RO_df_list.append(df)\n",
    "\n",
    "#Other of Kinect\n",
    "Kinect_Other_file_path = r'D:\\GoogleDrive\\Graduate\\Research\\Research_HsinWei\\Programs\\data\\KinectData\\Other'                     # use your path\n",
    "Kinect_Other_all_files = glob.glob(os.path.join(Kinect_Other_file_path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "Kinect_Other_df_list = []\n",
    "\n",
    "for index, f in enumerate(Kinect_Other_all_files):\n",
    "    df = pd.read_csv(f, header=None)\n",
    "    df.columns = ['WristRight_x', 'WristRight_y', 'WristRight_z', \n",
    "                  'WristLeft_x', 'WristLeft_y', 'WristLeft_z', \n",
    "                  'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z',\n",
    "                  'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "                  'ShoulderRight_x', 'ShoulderRight_y', 'ShoulderRight_z',\n",
    "                  'ShoulderLeft_x', 'ShoulderLeft_y', 'ShoulderLeft_z',\n",
    "                  'SkeletonID', 'Head_image_x', 'Head_image_y', 'timestamp']\n",
    "    Kinect_Other_df_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reach out data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取出各個reach out 的sample段 to list that each of element is np.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. IMU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IMU data of reaching out have 65 sample\n"
     ]
    }
   ],
   "source": [
    "IMU_RO_sampleAll = []\n",
    "# i = 0\n",
    "for index, IMU_RO_raw_pd in enumerate(IMU_RO_df_list):\n",
    "    sampleCount = [x for x in np.unique(IMU_RO_raw_pd['sampleNum'].values) if not math.isnan(x)]\n",
    "    for count in sampleCount:\n",
    "        IMU_RO_sampleAll.append(IMU_RO_raw_pd.loc[IMU_RO_raw_pd['sampleNum']==count, ['x', 'y', 'z']].values)\n",
    "#         print(i, count)\n",
    "#         i += 1\n",
    "\n",
    "print(\"Training IMU data of reaching out have %d sample\" % len(IMU_RO_sampleAll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Kinect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Kinect data of reaching out have 144 sample\n"
     ]
    }
   ],
   "source": [
    "Kinect_RO_sampleAll = []\n",
    "# i = 0\n",
    "for index, Kinect_RO_raw_pd in enumerate(Kinect_RO_df_list):\n",
    "    sampleCount = [x for x in np.unique(Kinect_RO_raw_pd['sampleNum'].values) if not math.isnan(x)]\n",
    "    for count in sampleCount:\n",
    "        Kinect_RO_sampleAll.append(Kinect_RO_raw_pd.loc[Kinect_RO_raw_pd['sampleNum']==count, \n",
    "                 ['WristRight_x', 'WristRight_y', 'WristRight_z', \n",
    "                  'WristLeft_x', 'WristLeft_y', 'WristLeft_z', \n",
    "                  'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z',\n",
    "                  'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "                  'ShoulderRight_x', 'ShoulderRight_y', 'ShoulderRight_z',\n",
    "                  'ShoulderLeft_x', 'ShoulderLeft_y', 'ShoulderLeft_z']].values)\n",
    "#         print(i, count)\n",
    "#         i += 1\n",
    "\n",
    "print(\"Training Kinect data of reaching out have %d sample\" % len(Kinect_RO_sampleAll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate windows size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How much samples in one sec (Must need even)\n",
    "sampleRate_IMU = 100\n",
    "sampleRate_Kinect = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取最平均值↓↓↓↓↓↓↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU window:  3.0\n",
      "Kinect window:  2.0\n",
      "Windows Size = 3\n"
     ]
    }
   ],
   "source": [
    "#IMU\n",
    "windowSize_IMU_sa = 0\n",
    "lenTemp = []\n",
    "for IMU_RO_sample in IMU_RO_sampleAll:\n",
    "    lenTemp.append(len(IMU_RO_sample))\n",
    "\n",
    "windowSize_IMU_sa = np.mean(lenTemp)\n",
    "windowSize_IMU = -(-(windowSize_IMU_sa)//sampleRate_IMU)\n",
    "print ('IMU window: ', windowSize_IMU)\n",
    "\n",
    "#Kinect    \n",
    "windowSize_Kinect_sa = 0\n",
    "lenTemp = []\n",
    "for Kinect_RO_sample in Kinect_RO_sampleAll:\n",
    "    lenTemp.append(len(Kinect_RO_sample))\n",
    "\n",
    "windowSize_Kinect_sa = np.mean(lenTemp)  \n",
    "windowSize_Kinect = -(-(windowSize_Kinect_sa)//sampleRate_Kinect)\n",
    "print ('Kinect window: ', windowSize_Kinect)\n",
    "        \n",
    "#Convert to sec\n",
    "windowSize_sec = max(windowSize_IMU, windowSize_Kinect)\n",
    "\n",
    "windowSize_sec = int(windowSize_sec)\n",
    "\n",
    "print ('Windows Size = %d' % windowSize_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取最大值↓↓↓↓↓↓↓↓↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #IMU\n",
    "# windowSize_IMU_sa = 0\n",
    "# for IMU_RO_sample in IMU_RO_sampleAll:\n",
    "#     if windowSize_IMU_sa < IMU_RO_sample.shape[0]:\n",
    "#         windowSize_IMU_sa = IMU_RO_sample.shape[0]\n",
    "        \n",
    "# windowSize_IMU = -(-(windowSize_IMU_sa)//sampleRate_IMU)\n",
    "# print ('IMU window: ', windowSize_IMU)\n",
    "\n",
    "# #Kinect    \n",
    "# windowSize_Kinect_sa = 0\n",
    "# for Kinect_RO_sample in Kinect_RO_sampleAll:\n",
    "#     if windowSize_Kinect_sa < Kinect_RO_sample.shape[0]:\n",
    "#         windowSize_Kinect_sa = Kinect_RO_sample.shape[0]\n",
    "\n",
    "# windowSize_Kinect = -(-(windowSize_Kinect_sa)//sampleRate_Kinect)\n",
    "# print ('Kinect window: ', windowSize_Kinect)\n",
    "        \n",
    "# #Convert to sec\n",
    "# windowSize_sec = max(windowSize_IMU, windowSize_Kinect)\n",
    "\n",
    "# windowSize_sec = int(windowSize_sec)\n",
    "\n",
    "# # windowSize_sec = 3\n",
    "# print ('Windows Size = %d' % windowSize_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut other data by windows size (overlapping half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IMU data of Other have 180 sample\n",
      "Training Kinect data of Other have 114 sample\n"
     ]
    }
   ],
   "source": [
    "#IMU other data\n",
    "IMU_Other_sampleAll = []\n",
    "for index, IMU_Other_raw_pd in enumerate(IMU_Other_df_list):\n",
    "    ranges = list(range(0, IMU_Other_raw_pd.shape[0], windowSize_sec*sampleRate_IMU//2))\n",
    "    for start in ranges:\n",
    "        end = start+windowSize_sec*sampleRate_IMU\n",
    "        if end >= len(IMU_Other_raw_pd):\n",
    "            continue\n",
    "        IMU_Other_sampleAll.append(IMU_Other_raw_pd.loc[start:end-1, ['x', 'y', 'z']].values)\n",
    "\n",
    "print(\"Training IMU data of Other have %d sample\" % len(IMU_Other_sampleAll))\n",
    "\n",
    "#Kinect other data\n",
    "Kinect_Other_sampleAll = []\n",
    "for index, Kinect_Other_raw_pd in enumerate(Kinect_Other_df_list):\n",
    "    ranges = list(range(0, Kinect_Other_raw_pd.shape[0], windowSize_sec*sampleRate_Kinect//2))\n",
    "    for start in ranges:\n",
    "        end = start+windowSize_sec*sampleRate_Kinect\n",
    "        if end >= len(Kinect_Other_raw_pd):\n",
    "            continue\n",
    "        Kinect_Other_sampleAll.append(Kinect_Other_raw_pd.loc[start:end-1, \n",
    "                 ['WristRight_x', 'WristRight_y', 'WristRight_z', \n",
    "                  'WristLeft_x', 'WristLeft_y', 'WristLeft_z', \n",
    "                  'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z',\n",
    "                  'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "                  'ShoulderRight_x', 'ShoulderRight_y', 'ShoulderRight_z',\n",
    "                  'ShoulderLeft_x', 'ShoulderLeft_y', 'ShoulderLeft_z']].values)\n",
    "\n",
    "print(\"Training Kinect data of Other have %d sample\" % len(Kinect_Other_sampleAll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Kinect data, Convert coordinate to attributes that are distance & angle (Just two attributes, need more..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For angle function based on Kinect coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Kinect's attribute: 19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def conv2attr_kinect(Kinect_sample): #(N, N)\n",
    "    Kinect_sample_conv = []\n",
    "    for Kinect_sample_sample in Kinect_sample:\n",
    "        WR = Kinect_sample_sample[0:3]\n",
    "        WL = Kinect_sample_sample[3:6]\n",
    "        ER = Kinect_sample_sample[6:9]\n",
    "        EL = Kinect_sample_sample[9:12]\n",
    "        SR = Kinect_sample_sample[12:15]\n",
    "        SL = Kinect_sample_sample[15:18]\n",
    "        \n",
    "        WR_ER_dist = euclidean_distances([WR], [ER])[0][0]\n",
    "        WR_SR_dist = euclidean_distances([WR], [SR])[0][0]\n",
    "        WR_WL_dist = euclidean_distances([WR], [WL])[0][0]\n",
    "        WR_EL_dist = euclidean_distances([WR], [EL])[0][0]\n",
    "        WR_SL_dist = euclidean_distances([WR], [SL])[0][0]\n",
    "        ER_SR_dist = euclidean_distances([ER], [SR])[0][0]\n",
    "        ER_WL_dist = euclidean_distances([ER], [WL])[0][0]\n",
    "        ER_EL_dist = euclidean_distances([ER], [EL])[0][0]\n",
    "        ER_SL_dist = euclidean_distances([ER], [SL])[0][0]\n",
    "        SR_WL_dist = euclidean_distances([SR], [WL])[0][0]\n",
    "        SR_EL_dist = euclidean_distances([SR], [EL])[0][0]\n",
    "        SR_SL_dist = euclidean_distances([SR], [SL])[0][0]\n",
    "        WL_EL_dist = euclidean_distances([WL], [EL])[0][0]\n",
    "        WL_SL_dist = euclidean_distances([WL], [SL])[0][0]\n",
    "        EL_SL_dist = euclidean_distances([EL], [SL])[0][0]\n",
    "        \n",
    "        SR2WR_SR2SL_angle = angle_between(WR-SR, SL-SR)\n",
    "        SR2ER_SR2SL_angle = angle_between(ER-SR, SL-SR)\n",
    "        SL2WL_SL2SR_angle = angle_between(WL-SL, SR-SL)\n",
    "        SL2EL_SL2SR_angle = angle_between(EL-SL, SR-SL)\n",
    "        \n",
    "        Kinect_sample_conv.append([WR_ER_dist, WR_SR_dist, WR_WL_dist, \n",
    "                           WR_EL_dist, WR_SL_dist, ER_SR_dist, \n",
    "                           ER_WL_dist, ER_EL_dist, ER_SL_dist,\n",
    "                           SR_WL_dist, SR_EL_dist, SR_SL_dist, \n",
    "                           WL_EL_dist, WL_SL_dist, EL_SL_dist,\n",
    "                           SR2WR_SR2SL_angle, SR2ER_SR2SL_angle, \n",
    "                           SL2WL_SL2SR_angle, SL2EL_SL2SR_angle])\n",
    "    \n",
    "    return np.array(Kinect_sample_conv)\n",
    "\n",
    "# #RO\n",
    "# Kinect_RO_sampleAll_conv = []\n",
    "# for Kinect_RO_sample in Kinect_RO_sampleAll:\n",
    "#     tempsample = []\n",
    "#     for Kinect_RO_sample_sample in Kinect_RO_sample:\n",
    "#         tempsample.append(euclidean_distances([Kinect_RO_sample_sample[0:3]], [Kinect_RO_sample_sample[12:15]])[0][0])\n",
    "#         tempsample_np = np.array(tempsample)\n",
    "#         tempsample_np = tempsample_np[:, np.newaxis]\n",
    "#     Kinect_RO_sampleAll_conv.append(tempsample_np)\n",
    "    \n",
    "# #Other\n",
    "# Kinect_Other_sampleAll_conv = []\n",
    "# for Kinect_Other_sample in Kinect_Other_sampleAll:\n",
    "#     tempsample = []\n",
    "#     for Kinect_Other_sample_sample in Kinect_Other_sample:\n",
    "#         tempsample.append(euclidean_distances([Kinect_Other_sample_sample[0:3]], [Kinect_Other_sample_sample[12:15]])[0][0])\n",
    "#         tempsample_np = np.array(tempsample)\n",
    "#         tempsample_np = tempsample_np[:, np.newaxis]\n",
    "#     Kinect_Other_sampleAll_conv.append(tempsample_np)\n",
    "    \n",
    "Kinect_RO_sampleAll_conv = []\n",
    "\n",
    "for Kinect_RO_sample in Kinect_RO_sampleAll:\n",
    "    Kinect_RO_sampleAll_conv.append(conv2attr_kinect(Kinect_RO_sample))\n",
    "    \n",
    "Kinect_Other_sampleAll_conv = []\n",
    "\n",
    "for Kinect_Other_sample in Kinect_Other_sampleAll:\n",
    "    Kinect_Other_sampleAll_conv.append(conv2attr_kinect(Kinect_Other_sample))\n",
    "    \n",
    "print('Number of Kinect\\'s attribute:', len(Kinect_RO_sampleAll_conv[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature of IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "def extract_feature_IMU(IMU_sample): #input np.array shape = (N, 3)\n",
    "\n",
    "    ##Mean (1, 3)\n",
    "    IMU_mean = np.mean(IMU_sample, axis=0) \n",
    "    \n",
    "    ##Skewness\n",
    "    IMU_skew = skew(IMU_sample, axis=0)\n",
    "    \n",
    "    ##Kurtosis\n",
    "    IMU_kurtosis = kurtosis(IMU_sample, axis=0)\n",
    "    \n",
    "    ##Mean Magnitude (1,)\n",
    "    summ = 0.0\n",
    "    for IMU_sample_sample in IMU_sample:\n",
    "        tempSqur = 0.0\n",
    "        for i in range(0, len(IMU_sample_sample)):\n",
    "            tempSqur += IMU_sample_sample[i]**2\n",
    "        summ = tempSqur**0.5\n",
    "    IMU_MM = (summ/IMU_sample.shape[0])\n",
    "\n",
    "    ##Variance (1, 3)\n",
    "    IMU_var = np.var(IMU_sample, axis=0) \n",
    "\n",
    "    ##Median (1, 3)\n",
    "    IMU_median = np.median(IMU_sample, axis=0)\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    #\n",
    "    \n",
    "    #-------------------------------------------\n",
    "    #Time feature\n",
    "\n",
    "    ##Mean of 1 sec (1, 3*windowSize)...\n",
    "    #feature count is windowsSize/sec. \n",
    "    #Each of mean of reaching out are 100 samples.\n",
    "    oneSample = []\n",
    "    for start in range(0, windowSize_sec*sampleRate_IMU, sampleRate_IMU):\n",
    "        end = start + sampleRate_IMU\n",
    "        tempSamples = IMU_sample[start:end]\n",
    "        oneSample.extend(np.mean(tempSamples, axis=0).tolist())\n",
    "    IMU_meanOf1sec = oneSample\n",
    "\n",
    "    #combine together\n",
    "    features = []\n",
    "    features.extend(IMU_mean.tolist())\n",
    "    features.extend(IMU_skew.tolist())\n",
    "    features.extend(IMU_kurtosis.tolist())\n",
    "    features.append(IMU_MM)\n",
    "    features.extend(IMU_var.tolist())\n",
    "    features.extend(IMU_median.tolist())\n",
    "    features.extend(IMU_meanOf1sec)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature of Kinect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature_Kinect(Kinect_sample): #input np.array shape = (N, ?)\n",
    "    ##Mean\n",
    "    Kinect_mean = np.mean(Kinect_sample, axis=0)\n",
    "    \n",
    "    ##Skewness\n",
    "    Kinect_skew = skew(Kinect_sample, axis=0)\n",
    "    \n",
    "    ##Kurtosis\n",
    "    Kinect_kurtosis = kurtosis(Kinect_sample, axis=0)\n",
    "\n",
    "    ##Mean Magnitude\n",
    "    summ = 0.0\n",
    "    for Kinect_sample_sample in Kinect_sample:\n",
    "        tempSqur = 0.0\n",
    "        for i in range(0, len(Kinect_sample_sample)):\n",
    "            tempSqur += Kinect_sample_sample[i]**2\n",
    "        summ = tempSqur**0.5\n",
    "    Kinect_MM = (summ/Kinect_sample.shape[0])\n",
    "    \n",
    "    ##Variance\n",
    "    Kinect_var = np.var(Kinect_sample, axis=0)\n",
    "\n",
    "    ##Median\n",
    "    Kinect_median = np.median(Kinect_sample, axis=0)\n",
    "\n",
    "    ##Mean of 1 sec\n",
    "    #feature count is windowsSize/sec. \n",
    "    #Each of mean of reaching out are 24 samples. 不夠的設為0 \n",
    "    oneSample = []\n",
    "    for start in range(0, windowSize_sec*sampleRate_Kinect, sampleRate_Kinect):\n",
    "        end = start + sampleRate_Kinect\n",
    "        tempSamples = Kinect_sample[start:end]\n",
    "        oneSample.extend(np.mean(tempSamples, axis=0).tolist())\n",
    "    Kinect_meanOf1sec = oneSample\n",
    "    \n",
    "    #combine together\n",
    "    features = []\n",
    "    features.extend(Kinect_mean.tolist())\n",
    "    features.extend(Kinect_skew.tolist())\n",
    "    features.extend(Kinect_kurtosis.tolist())\n",
    "    features.append(Kinect_MM)\n",
    "    features.extend(Kinect_var.tolist())\n",
    "    features.extend(Kinect_median.tolist())\n",
    "    features.extend(Kinect_meanOf1sec)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補足data長度到windows size(前後補)&Split data into Training, Validation and Testing(6/2/2) & Standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleRate_IMU*windowSize_sec-len(IMU_RO_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_IMU = []\n",
    "y_IMU = []\n",
    "\n",
    "#add RO into X_IMU & y_IMU\n",
    "for IMU_RO_sample in IMU_RO_sampleAll:\n",
    "    lengthOflack = sampleRate_IMU*windowSize_sec-len(IMU_RO_sample)\n",
    "    if lengthOflack > 0:\n",
    "        IMU_RO_sample_filltoprior = np.concatenate( \n",
    "                                  ([IMU_RO_sample[0].tolist()] * lengthOflack, IMU_RO_sample),\n",
    "                                  axis=0)\n",
    "        IMU_RO_sample_filltoPandR = np.concatenate(\n",
    "                                  ([IMU_RO_sample[0].tolist()] * (lengthOflack//2), IMU_RO_sample, [IMU_RO_sample[-1].tolist()] * (-(-lengthOflack//2))), \n",
    "                                  axis=0)\n",
    "        IMU_RO_sample_filltorear = np.concatenate(\n",
    "                                  (IMU_RO_sample, [IMU_RO_sample[-1].tolist()] * lengthOflack), \n",
    "                                  axis=0)\n",
    "    else:\n",
    "        IMU_RO_sample_filltoprior = IMU_RO_sample\n",
    "        IMU_RO_sample_filltoPandR = IMU_RO_sample\n",
    "        IMU_RO_sample_filltorear = IMU_RO_sample\n",
    "    features_prior = extract_feature_IMU(IMU_RO_sample_filltoprior)\n",
    "    features_PandR = extract_feature_IMU(IMU_RO_sample_filltoPandR)\n",
    "    features_rear = extract_feature_IMU(IMU_RO_sample_filltorear)\n",
    "    #add into X_IMU\n",
    "    X_IMU.append(features_prior)\n",
    "    y_IMU.append(1)\n",
    "    X_IMU.append(features_PandR)\n",
    "    y_IMU.append(1)\n",
    "    X_IMU.append(features_rear)\n",
    "    y_IMU.append(1)\n",
    "\n",
    "#add Other into X_IMU & y_IMU\n",
    "for IMU_Other_sample in IMU_Other_sampleAll:\n",
    "    features = extract_feature_IMU(IMU_Other_sample)\n",
    "    #add into X\n",
    "    X_IMU.append(features)\n",
    "    y_IMU.append(0)\n",
    "    \n",
    "\n",
    "##Split X_IMU, y_IMU into training and testing(6/2/2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_IMU_train, X_IMU_test, y_IMU_train, y_IMU_test = train_test_split(X_IMU, y_IMU, test_size=0.2, random_state=0)\n",
    "# X_IMU_train, X_IMU_val, y_IMU_train, y_IMU_val = train_test_split(X_IMU_train, y_IMU_train, test_size=0.25, random_state=0)\n",
    "X_IMU_train, X_IMU_val, y_IMU_train, y_IMU_val = train_test_split(X_IMU, y_IMU, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "#Standard\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_IMU = StandardScaler()\n",
    "sc_IMU.fit(X_IMU_train)\n",
    "X_IMU_train_std = sc_IMU.transform(X_IMU_train)\n",
    "X_IMU_val_std = sc_IMU.transform(X_IMU_val)\n",
    "# X_IMU_test_std = sc_IMU.transform(X_IMU_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kinect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Kinect = []\n",
    "y_Kinect = []\n",
    "\n",
    "#add RO into X_Kinect & y_Kinect\n",
    "for Kinect_RO_sample_conv in Kinect_RO_sampleAll_conv:\n",
    "    lengthOflack = sampleRate_Kinect*windowSize_sec-len(Kinect_RO_sample_conv)\n",
    "    if lengthOflack > 0:\n",
    "        Kinect_RO_sample_filltoprior = np.concatenate( \n",
    "                                  ([Kinect_RO_sample_conv[0].tolist()] * lengthOflack, Kinect_RO_sample_conv),\n",
    "                                  axis=0)\n",
    "        Kinect_RO_sample_filltoPandR = np.concatenate(\n",
    "                                  ([Kinect_RO_sample_conv[0].tolist()] * (lengthOflack//2), Kinect_RO_sample_conv, [Kinect_RO_sample_conv[-1].tolist()] * (-(-lengthOflack//2))), \n",
    "                                  axis=0)\n",
    "        Kinect_RO_sample_filltorear = np.concatenate(\n",
    "                                  (Kinect_RO_sample_conv, [Kinect_RO_sample_conv[-1].tolist()] * lengthOflack), \n",
    "                                  axis=0)\n",
    "    else:\n",
    "        Kinect_RO_sample_filltoprior = Kinect_RO_sample_conv\n",
    "        Kinect_RO_sample_filltoPandR = Kinect_RO_sample_conv\n",
    "        Kinect_RO_sample_filltorear = Kinect_RO_sample_conv\n",
    "    features_prior = extract_feature_Kinect(Kinect_RO_sample_filltoprior)\n",
    "    features_PandR = extract_feature_Kinect(Kinect_RO_sample_filltoPandR)\n",
    "    features_rear = extract_feature_Kinect(Kinect_RO_sample_filltorear)\n",
    "    #add into X_Kinect\n",
    "    X_Kinect.append(features_prior)\n",
    "    y_Kinect.append(1)\n",
    "    X_Kinect.append(features_PandR)\n",
    "    y_Kinect.append(1)\n",
    "    X_Kinect.append(features_rear)\n",
    "    y_Kinect.append(1)\n",
    "\n",
    "#add Other into X_Kinect & y_Kinect\n",
    "for Kinect_Other_sample_conv in Kinect_Other_sampleAll_conv:\n",
    "    features = extract_feature_Kinect(Kinect_Other_sample_conv)\n",
    "    #add into X_Kinect\n",
    "    X_Kinect.append(features)\n",
    "    y_Kinect.append(0)\n",
    "    \n",
    "\n",
    "##Split X_Kinect, y_Kinect into training and testing(6/2/2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_Kinect_train, X_Kinect_test, y_Kinect_train, y_Kinect_test = train_test_split(X_Kinect, y_Kinect, test_size=0.2, random_state=2)\n",
    "# X_Kinect_train, X_Kinect_val, y_Kinect_train, y_Kinect_val = train_test_split(X_Kinect_train, y_Kinect_train, test_size=0.25, random_state=2)\n",
    "X_Kinect_train, X_Kinect_val, y_Kinect_train, y_Kinect_val = train_test_split(X_Kinect, y_Kinect, test_size=0.3, random_state=2)\n",
    "\n",
    "\n",
    "#Standard\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_Kinect = StandardScaler()\n",
    "sc_Kinect.fit(X_Kinect_train)\n",
    "X_Kinect_train_std = sc_Kinect.transform(X_Kinect_train)\n",
    "X_Kinect_val_std = sc_Kinect.transform(X_Kinect_val)\n",
    "# X_Kinect_test_std = sc_Kinect.transform(X_Kinect_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data的比率 of IMU\n",
      "{0: 125, 1: 137}\n",
      "Training data的比率 of Kinect\n",
      "{0: 81, 1: 301}\n"
     ]
    }
   ],
   "source": [
    "print('Training data的比率 of IMU')\n",
    "uni ,count = np.unique(y_IMU_train, return_counts=True)\n",
    "print (dict(zip(uni, count)))\n",
    "\n",
    "print('Training data的比率 of Kinect')\n",
    "uni ,count = np.unique(y_Kinect_train, return_counts=True)\n",
    "print (dict(zip(uni, count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 丟入model 看結果(緊張..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Decision Tree=======\n",
      "[IMU performance]\n",
      "Validation accuracy: 0.94\n",
      "\n",
      "[Kinect performance]\n",
      "Validation accuracy: 0.96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/tree_Kinect.pkl']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('======Decision Tree=======')\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# criterion : impurity function\n",
    "# max_depth : maximum depth of tree\n",
    "# random_state : seed of random number generator\n",
    "##IMU\n",
    "tree_IMU = DecisionTreeClassifier(criterion='entropy', \n",
    "                              max_depth=7, \n",
    "                              random_state=0)\n",
    "tree_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "print('[IMU performance]')\n",
    "#Validation\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_IMU_pred = tree_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = tree_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "##Kinect\n",
    "tree_Kinect = DecisionTreeClassifier(criterion='gini', \n",
    "                                     splitter='random',\n",
    "                                     max_depth=None,\n",
    "                                     min_samples_split=12 ,\n",
    "                                     random_state=5)\n",
    "tree_Kinect.fit(X_Kinect_train_std, y_Kinect_train)\n",
    "\n",
    "print('\\n[Kinect performance]')\n",
    "#Validation\n",
    "y_Kinect_pred = tree_Kinect.predict(X_Kinect_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_Kinect_val, y_Kinect_pred))\n",
    "#Testing\n",
    "# y_Kinect_pred = tree_Kinect.predict(X_Kinect_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_Kinect_test, y_Kinect_pred))\n",
    "\n",
    "#Persist model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(tree_IMU, './models/tree_IMU.pkl')\n",
    "joblib.dump(tree_Kinect, './models/tree_Kinect.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Random Forest=======\n",
      "[IMU performance]\n",
      "Validation accuracy: 0.96\n",
      "\n",
      "[Kinect performance]\n",
      "Validation accuracy: 0.99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/forest_Kinect.pkl']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('======Random Forest=======')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# criterion : impurity function\n",
    "# n_estimators :  number of decision trees\n",
    "# random_state : seed used by the random number generator\n",
    "# n_jobs : number of cores for parallelism\n",
    "#IMU\n",
    "forest_IMU = RandomForestClassifier(criterion='entropy',\n",
    "                                max_depth=7,\n",
    "                                n_estimators=200, \n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "forest_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "print('[IMU performance]')\n",
    "#Validation\n",
    "y_IMU_pred = forest_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = forest_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "##Kinect\n",
    "forest_Kinect = RandomForestClassifier(criterion='entropy',\n",
    "                                max_depth=7,\n",
    "                                n_estimators=300, \n",
    "                                random_state=1,\n",
    "                                n_jobs=-1)\n",
    "forest_Kinect.fit(X_Kinect_train_std, y_Kinect_train)\n",
    "\n",
    "print('\\n[Kinect performance]')\n",
    "#Validation\n",
    "y_Kinect_pred = forest_Kinect.predict(X_Kinect_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_Kinect_val, y_Kinect_pred))\n",
    "#Testing\n",
    "# y_Kinect_pred = forest_Kinect.predict(X_Kinect_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_Kinect_test, y_Kinect_pred))\n",
    "\n",
    "#Persist model\n",
    "joblib.dump(forest_IMU, './models/forest_IMU.pkl')\n",
    "joblib.dump(forest_Kinect, './models/forest_Kinect.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======KNN=======\n",
      "[IMU performance]\n",
      "Validation accuracy: 0.99\n",
      "\n",
      "[Kinect performance]\n",
      "Validation accuracy: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/knn_Kinect.pkl']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('======KNN=======')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# p=2 and metric='minkowski' means the Euclidean Distance\n",
    "##IMU\n",
    "knn_IMU = KNeighborsClassifier(n_neighbors=3, p=2, metric='minkowski')\n",
    "\n",
    "knn_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "print('[IMU performance]')\n",
    "#Validation\n",
    "y_IMU_pred = knn_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = knn_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "##Kinect\n",
    "knn_Kinect = KNeighborsClassifier(n_neighbors=2, p=1, metric='minkowski')\n",
    "\n",
    "knn_Kinect.fit(X_Kinect_train_std, y_Kinect_train)\n",
    "\n",
    "print('\\n[Kinect performance]')\n",
    "#Validation\n",
    "y_Kinect_pred = knn_Kinect.predict(X_Kinect_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_Kinect_val, y_Kinect_pred))\n",
    "#Testing\n",
    "# y_Kinect_pred = knn_Kinect.predict(X_Kinect_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_Kinect_test, y_Kinect_pred))\n",
    "\n",
    "#Persist model\n",
    "joblib.dump(knn_IMU, './models/knn_IMU.pkl')\n",
    "joblib.dump(knn_Kinect, './models/knn_Kinect.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====SVM=======\n",
      "#[IMU performance]#\n",
      "[Linear SVC]\n",
      "Validation accuracy: 0.94\n",
      "[Poly SVC]\n",
      "Validation accuracy: 0.99\n",
      "[rbf SVC]\n",
      "Validation accuracy: 0.99\n",
      "\n",
      "#[Kinect performance]#\n",
      "[Linear SVC]\n",
      "Validation accuracy: 0.98\n",
      "[Poly SVC]\n",
      "Validation accuracy: 0.92\n",
      "[rbf SVC]\n",
      "Validation accuracy: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/svm_rbf_Kinect.pkl']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('=====SVM=======')\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# kernel: the kernel function, can be 'linear', 'poly', 'rbf', ...etc\n",
    "# C is the hyperparameter for the error penalty term\n",
    "##IMU\n",
    "svm_linear_IMU = SVC(kernel='linear', C=10000.0, random_state=0)\n",
    "\n",
    "svm_linear_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "print('#[IMU performance]#')\n",
    "#Validation\n",
    "print('[Linear SVC]')\n",
    "y_IMU_pred = svm_linear_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = svm_linear_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "##poly\n",
    "svm_poly_IMU = SVC(kernel='poly', C=1000.0, random_state=0)\n",
    "\n",
    "svm_poly_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "#Validation\n",
    "print('[Poly SVC]')\n",
    "y_IMU_pred = svm_poly_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = svm_poly_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "##rbf\n",
    "svm_rbf_IMU = SVC(kernel='rbf', C=10000.0, random_state=0)\n",
    "\n",
    "svm_rbf_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "#Validation\n",
    "print('[rbf SVC]')\n",
    "y_IMU_pred = svm_rbf_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "#Testing\n",
    "# y_IMU_pred = svm_rbf_IMU.predict(X_IMU_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_IMU_test, y_IMU_pred))\n",
    "\n",
    "##Kinect\n",
    "svm_linear_Kinect = SVC(kernel='linear', C=10000.0, random_state=0)\n",
    "\n",
    "svm_linear_Kinect.fit(X_Kinect_train_std, y_Kinect_train)\n",
    "\n",
    "print('\\n#[Kinect performance]#')\n",
    "#Validation\n",
    "print('[Linear SVC]')\n",
    "y_Kinect_pred = svm_linear_Kinect.predict(X_Kinect_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_Kinect_val, y_Kinect_pred))\n",
    "#Testing\n",
    "# y_Kinect_pred = svm_linear_Kinect.predict(X_Kinect_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_Kinect_test, y_Kinect_pred))\n",
    "\n",
    "##poly\n",
    "svm_poly_Kinect = SVC(kernel='poly', C=1000.0, random_state=0)\n",
    "\n",
    "svm_poly_Kinect.fit(X_Kinect_train_std, y_Kinect_train)\n",
    "\n",
    "#Validation\n",
    "print('[Poly SVC]')\n",
    "y_Kinect_pred = svm_poly_Kinect.predict(X_Kinect_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_Kinect_val, y_Kinect_pred))\n",
    "#Testing\n",
    "# y_Kinect_pred = svm_poly_Kinect.predict(X_Kinect_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_Kinect_test, y_Kinect_pred))\n",
    "\n",
    "##rbf\n",
    "svm_rbf_Kinect = SVC(kernel='rbf', C=10000.0, random_state=0)\n",
    "\n",
    "svm_rbf_Kinect.fit(X_Kinect_train_std, y_Kinect_train)\n",
    "\n",
    "#Validation\n",
    "print('[rbf SVC]')\n",
    "y_Kinect_pred = svm_rbf_Kinect.predict(X_Kinect_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_Kinect_val, y_Kinect_pred))\n",
    "#Testing\n",
    "# y_Kinect_pred = svm_rbf_Kinect.predict(X_Kinect_test_std)\n",
    "# print('Testing accuracy: %.2f' % accuracy_score(y_Kinect_test, y_Kinect_pred))\n",
    "\n",
    "\n",
    "#Persist model\n",
    "joblib.dump(svm_linear_IMU, './models/svm_linear_IMU.pkl')\n",
    "joblib.dump(svm_poly_IMU, './models/svm_poly_IMU.pkl')\n",
    "joblib.dump(svm_rbf_IMU, './models/svm_rbf_IMU.pkl')\n",
    "joblib.dump(svm_linear_Kinect, './models/svm_linear_Kinect.pkl')\n",
    "joblib.dump(svm_poly_Kinect, './models/svm_poly_Kinect.pkl')\n",
    "joblib.dump(svm_rbf_Kinect, './models/svm_rbf_Kinect.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======Neural network=======\n",
      "#[IMU performance]#\n",
      "Validation accuracy: 0.99\n",
      "#[Kinect performance]#\n",
      "Validation accuracy: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./models/NN_Kinect.pkl']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('======Neural network=======')\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "NN_IMU = MLPClassifier(solver='lbfgs', alpha=0.01, activation='logistic', learning_rate='constant', learning_rate_init=0.001,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "NN_IMU.fit(X_IMU_train_std, y_IMU_train)\n",
    "\n",
    "print('#[IMU performance]#')\n",
    "#Validation\n",
    "y_IMU_pred = NN_IMU.predict(X_IMU_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_IMU_val, y_IMU_pred))\n",
    "\n",
    "##Kinect\n",
    "NN_Kinect = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "NN_Kinect.fit(X_Kinect_train_std, y_Kinect_train)\n",
    "print('#[Kinect performance]#')\n",
    "#Validation\n",
    "y_IMU_pred = NN_Kinect.predict(X_Kinect_val_std)\n",
    "print('Validation accuracy: %.2f' % accuracy_score(y_Kinect_val, y_Kinect_pred))\n",
    "\n",
    "#Persist model\n",
    "joblib.dump(NN_IMU, './models/NN_IMU.pkl')\n",
    "joblib.dump(NN_Kinect, './models/NN_Kinect.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 2): 1.000 (+/- 0.000)\n",
      "(0, 2, 1): 1.000 (+/- 0.000)\n",
      "(1, 0, 2): 1.000 (+/- 0.000)\n",
      "(1, 2, 0): 0.998 (+/- 0.005)\n",
      "(2, 0, 1): 0.998 (+/- 0.005)\n",
      "(2, 1, 0): 0.997 (+/- 0.008)\n",
      "\n",
      "Best (0, 1, 2): 1.000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import itertools\n",
    "\n",
    "best_vt, best_w, best_score = None, (), -1\n",
    "for a, b, c in list(itertools.permutations(range(0, 3))):  # try some weight combination\n",
    "    voting_IMU = VotingClassifier(\n",
    "                        estimators=[('tree', tree_IMU), ('forest', forest_IMU), ('knn', knn_IMU)],\n",
    "                          voting='soft',\n",
    "                          weights=[a, b, c])\n",
    "    scores = cross_val_score(\n",
    "        estimator=voting_IMU, X=X_IMU_train_std, y=y_IMU_train, cv=10, scoring='roc_auc')\n",
    "    print('%s: %.3f (+/- %.3f)' % ((a, b, c), scores.mean(), scores.std()))\n",
    "    if best_score < scores.mean():\n",
    "        best_vt, best_w, best_score = voting_IMU, (a, b, c), scores.mean()\n",
    "\n",
    "print('\\nBest %s: %.3f' % (best_w, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating real world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "X_combined_IMU_All = []\n",
    "y_combined_IMU_All = []\n",
    "\n",
    "##先給0~100 Other then replace RO in random place\n",
    "for random_Other_sample in random.sample(IMU_Other_sampleAll, 30):\n",
    "    X_combined_IMU_All.append(random_Other_sample)\n",
    "    y_combined_IMU_All.append(0)\n",
    "\n",
    "insertROcount = 6\n",
    "for index, random_RO_sample in zip(np.random.randint(30, size=insertROcount), random.sample(IMU_RO_sampleAll, insertROcount)):\n",
    "    X_combined_IMU_All[index] = random_RO_sample\n",
    "    y_combined_IMU_All[index] = 1\n",
    "    \n",
    "##flatten\n",
    "X_combined_IMU_fla = []\n",
    "y_combined_IMU_fla = []\n",
    "\n",
    "for s, c in zip(X_combined_IMU_All, y_combined_IMU_All):\n",
    "    X_combined_IMU_fla.extend(s.tolist())\n",
    "    listofzerosOrOne = [c] * s.shape[0]\n",
    "    y_combined_IMU_fla.extend(listofzerosOrOne)\n",
    "    \n",
    "##Segmentation(by windows Size, and Overlapping= windows size - 1 sec)\n",
    "overlapping = windowSize_sec - 1\n",
    "X_combined_IMU_seg = []\n",
    "\n",
    "for start in range(0, len(X_combined_IMU_fla), windowSize_sec*sampleRate_IMU - overlapping*sampleRate_IMU):\n",
    "    end = start + sampleRate_IMU*windowSize_sec\n",
    "    if len(X_combined_IMU_fla[start:end]) < sampleRate_IMU*windowSize_sec:\n",
    "        continue\n",
    "    else:\n",
    "        X_combined_IMU_seg.append(X_combined_IMU_fla[start:end])\n",
    "        \n",
    "# ##feature extraction\n",
    "X_combined_IMU = []\n",
    "\n",
    "for X_combined_IMU_seg_sample in X_combined_IMU_seg:\n",
    "    X_combined_IMU.append(extract_feature_IMU(np.array(X_combined_IMU_seg_sample)))\n",
    "        \n",
    "##Normalization\n",
    "X_combined_IMU_std = sc_IMU.transform(X_combined_IMU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kinect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_combined_Kinect_All = []\n",
    "y_combined_Kinect_All = []\n",
    "\n",
    "##先給0~100 Other then replace RO in random place\n",
    "for random_Other_sample in random.sample(Kinect_Other_sampleAll, 30):\n",
    "    X_combined_Kinect_All.append(random_Other_sample)\n",
    "    y_combined_Kinect_All.append(0)\n",
    "\n",
    "insertROcount = 6\n",
    "for index, random_RO_sample in zip(np.random.randint(30, size=insertROcount), random.sample(Kinect_RO_sampleAll, insertROcount)):\n",
    "    X_combined_Kinect_All[index] = random_RO_sample\n",
    "    y_combined_Kinect_All[index] = 1\n",
    "    \n",
    "##flatten\n",
    "X_combined_Kinect_fla = []\n",
    "y_combined_Kinect_fla = []\n",
    "\n",
    "for s, c in zip(X_combined_Kinect_All, y_combined_Kinect_All):\n",
    "    X_combined_Kinect_fla.extend(s.tolist())\n",
    "    listofzerosOrOne = [c] * s.shape[0]\n",
    "    y_combined_Kinect_fla.extend(listofzerosOrOne)\n",
    "    \n",
    "##Segmentation(by windows Size, and Overlapping= windows size - 1 sec)\n",
    "overlapping = windowSize_sec - 1\n",
    "X_combined_Kinect_seg = []\n",
    "\n",
    "for start in range(0, len(X_combined_Kinect_fla), windowSize_sec*sampleRate_Kinect - overlapping*sampleRate_Kinect):\n",
    "    end = start + sampleRate_Kinect*windowSize_sec\n",
    "    if len(X_combined_Kinect_fla[start:end]) < sampleRate_Kinect*windowSize_sec:\n",
    "        continue\n",
    "    else:\n",
    "        X_combined_Kinect_seg.append(X_combined_Kinect_fla[start:end])\n",
    "\n",
    "#Preprocessing\n",
    "X_combined_Kinect_seg_conv = []\n",
    "for X_combined_Kinect_seg_sam in X_combined_Kinect_seg:\n",
    "    X_combined_Kinect_seg_conv.append(conv2attr_kinect(np.array(X_combined_Kinect_seg_sam)))\n",
    "        \n",
    "##feature extraction\n",
    "X_combined_Kinect = []\n",
    "\n",
    "for X_combined_Kinect_seg_sample in X_combined_Kinect_seg_conv:\n",
    "    X_combined_Kinect.append(extract_feature_Kinect(X_combined_Kinect_seg_sample))\n",
    "        \n",
    "##Normalization\n",
    "X_combined_Kinect_std = sc_Kinect.transform(X_combined_Kinect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input to models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#將Pred結果展開成sample比較 #Overlapping 實際執行秒數 = (Sec*Num)-[(Num-1)*Overlap]\n",
    "def pred_flatToSamples_IMU(y_pred):\n",
    "    allofSec = windowSize_sec*len(y_pred)-(len(y_pred)-1)*overlapping\n",
    "    y_pred_sample = [0] * (allofSec*sampleRate_IMU)\n",
    "    for pred, index in zip(y_pred, range(0, allofSec, windowSize_sec-overlapping)):\n",
    "        if pred == 1:\n",
    "            start = index*sampleRate_IMU\n",
    "            end = start + sampleRate_IMU*windowSize_sec\n",
    "            listofOne = [1] * (sampleRate_IMU*windowSize_sec)\n",
    "            y_pred_sample[start:end] = listofOne\n",
    "    return y_pred_sample\n",
    "\n",
    "def pred_flatToSamples_Kinect(y_pred):\n",
    "    allofSec = windowSize_sec*len(y_pred)-(len(y_pred)-1)*overlapping\n",
    "    y_pred_sample = [0] * (allofSec*sampleRate_Kinect)\n",
    "    for pred, index in zip(y_pred, range(0, allofSec, windowSize_sec-overlapping)):\n",
    "        if pred == 1:\n",
    "            start = index*sampleRate_Kinect\n",
    "            end = start + sampleRate_Kinect*windowSize_sec\n",
    "            listofOne = [1] * (sampleRate_Kinect*windowSize_sec)\n",
    "            y_pred_sample[start:end] = listofOne\n",
    "    return y_pred_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--IMU--\n",
      "Decision tree \n",
      "-DTW: 1343.0\n",
      "-Accuracy: 0.69\n",
      "Random forest \n",
      "-DTW: 373.0\n",
      "-Accuracy: 0.90\n",
      "KNN \n",
      "-DTW: 343.0\n",
      "-Accuracy: 0.75\n",
      "SVM linear \n",
      "-DTW: 590.0\n",
      "-Accuracy: 0.79\n",
      "SVM poly \n",
      "-DTW: 533.0\n",
      "-Accuracy: 0.90\n",
      "SVM rbf \n",
      "-DTW: 433.0\n",
      "-Accuracy: 0.82\n",
      "NN \n",
      "-DTW: 633.0\n",
      "-Accuracy: 0.82\n",
      "--Kinect--\n",
      "-Decistion tree \n",
      "-DTW: 0.0\n",
      "-Accuracy: 0.91\n",
      "-Random forest \n",
      "-DTW: 39.0\n",
      "-Accuracy: 0.94\n",
      "-KNN \n",
      "-DTW: 0.0\n",
      "-Accuracy: 0.91\n",
      "-SVM linear \n",
      "-DTW: 0.0\n",
      "-Accuracy: 0.93\n",
      "-SVM poly \n",
      "-DTW: 360.0\n",
      "-Accuracy: 0.66\n",
      "-SVM rbf \n",
      "-DTW: 51.0\n",
      "-Accuracy: 0.95\n",
      "-NN \n",
      "-DTW: 39.0\n",
      "-Accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "# %pylab inline\n",
    "\n",
    "print('--IMU--')\n",
    "tree_IMU = joblib.load('./models/tree_IMU.pkl')\n",
    "y_pred = tree_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "# plot(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis])\n",
    "# plot(np.array(y_pred_sample)[:,np.newaxis])\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('Decision tree \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "forest_IMU = joblib.load('./models/forest_IMU.pkl')\n",
    "y_pred = forest_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('Random forest \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "knn_IMU = joblib.load('./models/knn_IMU.pkl')\n",
    "y_pred = knn_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('KNN \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "svm_linear_IMU = joblib.load('./models/svm_linear_IMU.pkl')\n",
    "y_pred = svm_linear_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('SVM linear \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "svm_poly_IMU = joblib.load('./models/svm_poly_IMU.pkl')\n",
    "y_pred = svm_poly_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('SVM poly \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "svm_rbf_IMU = joblib.load('./models/svm_rbf_IMU.pkl')\n",
    "y_pred = svm_rbf_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('SVM rbf \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "NN_IMU = joblib.load('./models/NN_IMU.pkl')\n",
    "y_pred = NN_IMU.predict(X_combined_IMU_std)\n",
    "y_pred_sample = pred_flatToSamples_IMU(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_IMU_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('NN \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_IMU_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "##Kinect\n",
    "print('--Kinect--')\n",
    "tree_Kinect = joblib.load('./models/tree_Kinect.pkl')\n",
    "y_pred = tree_Kinect.predict(X_combined_Kinect_std)\n",
    "y_pred_sample = pred_flatToSamples_Kinect(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_Kinect_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('Decistion tree \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_Kinect_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "forest_Kinect = joblib.load('./models/forest_Kinect.pkl')\n",
    "y_pred = forest_Kinect.predict(X_combined_Kinect_std)\n",
    "y_pred_sample = pred_flatToSamples_Kinect(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_Kinect_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('Random forest \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_Kinect_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "knn_Kinect = joblib.load('./models/knn_Kinect.pkl')\n",
    "y_pred = knn_Kinect.predict(X_combined_Kinect_std)\n",
    "y_pred_sample = pred_flatToSamples_Kinect(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_Kinect_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('KNN \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_Kinect_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "svm_linear_Kinect = joblib.load('./models/svm_linear_Kinect.pkl')\n",
    "y_pred = svm_linear_Kinect.predict(X_combined_Kinect_std)\n",
    "y_pred_sample = pred_flatToSamples_Kinect(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_Kinect_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('SVM linear \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_Kinect_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "svm_poly_Kinect = joblib.load('./models/svm_poly_Kinect.pkl')\n",
    "y_pred = svm_poly_Kinect.predict(X_combined_Kinect_std)\n",
    "y_pred_sample = pred_flatToSamples_Kinect(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_Kinect_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('SVM poly \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_Kinect_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "svm_rbf_Kinect = joblib.load('./models/svm_rbf_Kinect.pkl')\n",
    "y_pred = svm_rbf_Kinect.predict(X_combined_Kinect_std)\n",
    "y_pred_sample = pred_flatToSamples_Kinect(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_Kinect_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('SVM rbf \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_Kinect_fla[:len(y_pred_sample)], y_pred_sample))\n",
    "\n",
    "NN_Kinect = joblib.load('./models/NN_Kinect.pkl')\n",
    "y_pred = NN_Kinect.predict(X_combined_Kinect_std)\n",
    "y_pred_sample = pred_flatToSamples_Kinect(y_pred)\n",
    "\n",
    "dist, path = fastdtw(np.array(y_combined_Kinect_fla[:len(y_pred_sample)])[:,np.newaxis], \n",
    "                            np.array(y_pred_sample)[:,np.newaxis], \n",
    "                            dist=euclidean)\n",
    "print('NN \\n-DTW:',dist)\n",
    "print('-Accuracy: %.2f' % accuracy_score(y_combined_Kinect_fla[:len(y_pred_sample)], y_pred_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1/0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiencing real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMU_rW_pd = pd.read_csv('D:/GoogleDrive/Graduate/Research/Research_HsinWei/Programs/data/realWorldData/IMU/raw_acc_01.csv', header=None)\n",
    "# IMU_rW_pd = pd.read_csv('D:/GoogleDrive/Graduate/Research/Research_HsinWei/Programs/data/IMUData/ReachOut/HW_raw_acc_RO_02.csv', header=None)\n",
    "\n",
    "IMU_rW_pd.columns = ['x', 'y', 'z', 'timestamp', 'ReachOut']\n",
    "\n",
    "IMU_rW = IMU_rW_pd[['x', 'y', 'z']].values.tolist()\n",
    "\n",
    "##Segmentation(by windows Size, and Overlapping= windows size - 1 sec)\n",
    "overlapping = windowSize_sec - 1\n",
    "X_rW_IMU_seg = []\n",
    "\n",
    "for start in range(0, len(IMU_rW), windowSize_sec*sampleRate_IMU - overlapping*sampleRate_IMU):\n",
    "    end = start + sampleRate_IMU*windowSize_sec\n",
    "    if len(IMU_rW[start:end]) < sampleRate_IMU*windowSize_sec:\n",
    "        break\n",
    "    else:\n",
    "        X_rW_IMU_seg.append(IMU_rW[start:end])\n",
    "        \n",
    "#Preprocessing\n",
    "X_rW_IMU_seg_conv = []\n",
    "for X_rW_IMU_seg_sam in X_rW_IMU_seg:\n",
    "    X_rW_IMU_seg_conv.append(X_rW_IMU_seg_sam)\n",
    "        \n",
    "##feature extraction\n",
    "X_rW_IMU = []\n",
    "for X_rW_IMU_seg_sample in X_rW_IMU_seg_conv:\n",
    "    X_rW_IMU.append(extract_feature_IMU(np.array(X_rW_IMU_seg_sample)))\n",
    "        \n",
    "##Normalization\n",
    "X_rW_IMU_std = sc_IMU.transform(X_rW_IMU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kinect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Kinect_rW_pd = pd.read_csv('D:/GoogleDrive/Graduate/Research/Research_HsinWei/Programs/data/realWorldData/Kinect/VSFile_01.csv', header=None)\n",
    "Kinect_rW_pd.columns = ['WristRight_x', 'WristRight_y', 'WristRight_z', \n",
    "                  'WristLeft_x', 'WristLeft_y', 'WristLeft_z', \n",
    "                  'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z',\n",
    "                  'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "                  'ShoulderRight_x', 'ShoulderRight_y', 'ShoulderRight_z',\n",
    "                  'ShoulderLeft_x', 'ShoulderLeft_y', 'ShoulderLeft_z',\n",
    "                  'SkeletonID', 'Head_image_x', 'Head_image_y', 'timestamp']\n",
    "\n",
    "Kinect_rW_pd_ntime = Kinect_rW_pd[['WristRight_x', 'WristRight_y', 'WristRight_z', \n",
    "                  'WristLeft_x', 'WristLeft_y', 'WristLeft_z', \n",
    "                  'ElbowRight_x', 'ElbowRight_y', 'ElbowRight_z',\n",
    "                  'ElbowLeft_x', 'ElbowLeft_y', 'ElbowLeft_z',\n",
    "                  'ShoulderRight_x', 'ShoulderRight_y', 'ShoulderRight_z',\n",
    "                  'ShoulderLeft_x', 'ShoulderLeft_y', 'ShoulderLeft_z',\n",
    "                  'SkeletonID', 'Head_image_x', 'Head_image_y']]\n",
    "\n",
    "Kinect_rW = Kinect_rW_pd_ntime.values.tolist()\n",
    "\n",
    "##Segmentation(by windows Size, and Overlapping= windows size - 1 sec)\n",
    "overlapping = windowSize_sec - 1\n",
    "X_rW_Kinect_seg = []\n",
    "\n",
    "for start in range(0, len(Kinect_rW), windowSize_sec*sampleRate_Kinect - overlapping*sampleRate_Kinect):\n",
    "    end = start + sampleRate_Kinect*windowSize_sec\n",
    "    if len(Kinect_rW[start:end]) < sampleRate_Kinect*windowSize_sec:\n",
    "        continue\n",
    "    else:\n",
    "        X_rW_Kinect_seg.append(Kinect_rW[start:end])\n",
    "        \n",
    "#Preprocessing\n",
    "X_rW_Kinect_seg_conv = []\n",
    "for X_rW_Kinect_seg_sam in X_rW_Kinect_seg:\n",
    "    X_rW_Kinect_seg_conv.append(conv2attr_kinect(np.array(X_rW_Kinect_seg_sam)))\n",
    "        \n",
    "##feature extraction\n",
    "X_rW_Kinect = []\n",
    "\n",
    "for X_rW_Kinect_seg_sample in X_rW_Kinect_seg_conv:\n",
    "    X_rW_Kinect.append(extract_feature_Kinect(X_rW_Kinect_seg_sample))\n",
    "        \n",
    "##Normalization\n",
    "X_rW_Kinect_std = sc_Kinect.transform(X_rW_Kinect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed into models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf_Kinect = joblib.load('./models/svm_rbf_Kinect.pkl')\n",
    "forest_Kinect.predict(X_rW_Kinect_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_linear_IMU.predict(X_rW_IMU_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_linear_Kinect.predict(X_rW_Kinect_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_IMU.predict(X_rW_IMU_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_Kinect.predict(X_rW_Kinect_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_IMU_pred = NN_IMU.predict(X_rW_IMU_std)\n",
    "\n",
    "y_kinect_pred = NN_Kinect.predict(X_rW_Kinect_std)\n",
    "\n",
    "\n",
    "IMU_sample_rw_pred = pred_flatToSamples_IMU(y_IMU_pred)\n",
    "Kinect_sample_rw_pred = pred_flatToSamples_Kinect(y_kinect_pred)\n",
    "\n",
    "# #Aligning\n",
    "# from datetime import datetime\n",
    "# IMU_rW_time = IMU_rW_pd['timestamp']\n",
    "# Kinect_rW_time = Kinect_rW_pd['timestamp']\n",
    "\n",
    "# startIndex_IMU = 0\n",
    "# start_Kinect = datetime.strptime(Kinect_rW_time[0], '%H:%M:%S:%f')\n",
    "# IMU_rW_time = pd.to_datetime(IMU_rW_time, format='%H:%M:%S:%f')\n",
    "# for index, IMU_timestamp in zip(range(0, len(IMU_rW_time)), IMU_rW_time):\n",
    "#     if IMU_timestamp < start_Kinect:\n",
    "#         continue\n",
    "#     else:\n",
    "#         startIndex_IMU = index\n",
    "#         break\n",
    "        \n",
    "# IMU_sample_rw_pred = IMU_sample_rw_pred[startIndex_IMU:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sign IMU result in Kinect video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sign IMU result in Kinect video\n",
    "IMU_result_inKinect = []\n",
    "\n",
    "IMU_rW_time = pd.to_datetime(IMU_rW_pd['timestamp'], format='%H:%M:%S:%f')\n",
    "Kinect_rW_time = pd.to_datetime(Kinect_rW_pd['timestamp'], format='%H:%M:%S:%f')\n",
    "i = 0\n",
    "for Kinect_rW_timestamp in Kinect_rW_time:\n",
    "    for si in range(i, len(IMU_rW_time)):\n",
    "        if IMU_rW_time[si] <= Kinect_rW_timestamp and Kinect_rW_timestamp < IMU_rW_time[si+1]:\n",
    "            IMU_result_inKinect.append(IMU_sample_rw_pred[i])\n",
    "            i = si\n",
    "            break\n",
    "            \n",
    "IMU_Kinect_sample_rw_pred = pd.DataFrame(np.array([IMU_result_inKinect, Kinect_sample_rw_pred]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to csv include result of predicting, headX_video, headY_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([IMU_Kinect_sample_rw_pred, Kinect_rW_pd[['Head_image_x', 'Head_image_y', 'timestamp']]], ignore_index=True, axis=1)\n",
    "\n",
    "result.to_csv('D:/GoogleDrive/Graduate/Research/Research_HsinWei/Programs/data/realWorldData/Kinect/ReachOutResult.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 測試真實的testing data看效果如何\n",
    "- IMU加更多的feature..(切更細的mean(O), Correlation, Covariance..)\n",
    "- Kinect加angle相關的atrribute, 並且座標zero點在自己身上,不會依據距離遠近而誤判\n",
    "- Kinect & IMU feature 合併的話??不是個別判斷\n",
    "- 程式部分\n",
    "    - 將extract feature寫成function(O)\n",
    "    - set sample/sec to var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE\n",
    "- 實驗重作...(O)\n",
    "- 程式部分\n",
    "    - 將extract feature寫成function(O)\n",
    "    - set sample/sec to var(O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to csv include percentage, headX_video, headY_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat([percentage, df[['HeadX_Video', 'HeadY_Video', 'TimeStamp']]], axis=1)\n",
    "\n",
    "result.to_csv('C:\\Research_temp\\data\\Result\\ReachOutResult.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "path = r'D:\\GoogleDrive\\Graduate\\Research\\Research_HsinWei\\Programs\\data\\IMUData\\ReachOut'                     # use your path\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a, b in range(10), range(11):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
